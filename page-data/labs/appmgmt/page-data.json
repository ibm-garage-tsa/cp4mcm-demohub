{"componentChunkName":"component---src-pages-labs-appmgmt-index-mdx","path":"/labs/appmgmt/","result":{"pageContext":{"frontmatter":{"title":"Lab 2 - Application Management","description":null},"relativePagePath":"/labs/appmgmt/index.mdx","titleType":"page","MdxNode":{"id":"08b0b45a-45e5-53c2-8fa8-57c6a2d75609","children":[],"parent":"25b639bf-4a97-54cf-90ea-ca4fa2c338b5","internal":{"content":"---\ntitle: Lab 2 - Application Management\ndescription:\n---\n\n<FeatureCard\n  title=\"Application Management with IBM Cloud Pak for Multicloud Management\"\n  color=\"dark\"\n  >\n\n![banner](/images/appmgmt-banner.jpg)\n\n</FeatureCard>\n\n\n<AnchorLinks>\n  <AnchorLink>Lab Overview</AnchorLink>\n  <AnchorLink>Prerequisite</AnchorLink>\n  <AnchorLink>Business Context</AnchorLink>\n  <AnchorLink>Define Application Channel</AnchorLink>\n  <AnchorLink>Create a Subscription</AnchorLink>\n  <AnchorLink>Deploy the Application</AnchorLink>\n  <AnchorLink>Validate the Application</AnchorLink>\n  <AnchorLink>Move the Application</AnchorLink>\n  <AnchorLink>Summary</AnchorLink>\n</AnchorLinks>\n\n***\n\n## Lab Overview\n\nIBM Cloud Pak for Multicloud Management provides consistent visibility, automation, and governance across a range of multicloud management capabilities such as cost and asset management, infrastructure management, application management, multi-cluster management, edge management, and integration with existing tools and processes. Customers can leverage Cloud Pak for Multicloud Management to simplify their IT and application ops management, while increasing flexibility and cost savings with intelligent data analysis driven by predictive signals.\n\nCustomers can leverage IBM Cloud Pak for Multicloud Management to simplify their IT and application ops management, while increasing flexibility and cost savings with intelligent data analysis driven by predictive signals.\n\nIn this tutorial, you will explore the following key capabilities:\n-\t`Understand Cloud Pak for Multicloud Management`\n-\t`Deploy an application using Channels and Subscriptions`\n-\t`Move the application between clusters using Placement Policies`\n-\t`Visualize the application health using Grafana dashboards`\n\n***\n\n## Prerequisite\n\n- You need to provision your own copy of the CP4MCM 2.0 environment, start it and verify for correct startup (check [here](../../gettingstarted/)).\n\n***\n\n## Business Context\n\nAs a member of the Cloud Operation team, you are having problems to manage your multicloud hybrid world. Operate your cloud-based services and data across multiple providers is overwhelming your team.\nYour company is deploying multiple Kubernetes clusters to address their specific needs. Some Dev teams are deploying clusters across public and private clouds, and some are deploying clusters across regions, and some are deploying clusters to support the development and test needs.\n\nAs different teams deploy more clusters, new challenges are introduced:\n-\tWhere are my services running?\n-\tHow can I monitor applications across clusters and clouds?\n-\tHow can I manage clusters as if they were one environment?\n-\tHow do I monitor usage across clouds?\n-\tWhere are the failed components?\n-\tHow do I deploy applications across these environments?\n-\tHow do I move workloads across environments?\n-\tHow do I set consistent security policies across environments?\n-\tWhich clusters are compliant?\n-\tHow can I place workloads based on capacity, policy?\n\nBecause of that, you want to explore how IBM Cloud Pak for Multicloud Management, provides consistent visibility, governance and automation of your complex environment.\n\nIBM Cloud Pak for Multicloud Management provides enhanced application management capabilities through an improved application model and deployment options. The concept helps simplify and streamline application life cycle management across clusters.\n\nIn this tutorial, you will be using a sample Modresort application to demonstrate how to deploy an application in multiple clusters using channels and subscriptions. The Modresort is a WebSphere Liberty Java application available in Dockerhub.\n\n![](images/1-app-mgmt-img.png)\n\nIn this tutorial, you use two Red Hat OpenShift clusters.\n-\tHub-cluster is the Hub cluster that includes management console, federated monitoring, and all the controllers. In this Lab, you identify the hub-cluster with the label Dev for environment.\n-\tManaged-cluster is an Openshift cluster managed by the Hub cluster. In this Lab, you identify the managed cluster with the label QA for environment\n\nYou will complete the following tasks:\n-\t`Deploy Modresort application using Channels and Subscriptions`\n-\t`Move the application between clusters using Placement Policies`\n-\t`Visualize application health by using Grafana dashboard`\n\n***\n\n## Add Managed Clusters\n\nIn this section, you will add two new managed clusters in your Control Panel. As explained before, you will add your OpenShift Hub cluster and your Microk8s managed cluster.\n\n1. To start the lab, you should be in your Cloud Pak for Multicloud Management Web Console. If you are not, check [here](../gettingstarted/) how to open your console page.\n\n  ![](images/2-cluster-mgmt-img.png)\n\n2. Now, let's explore the Cluster view. Click the hamburger **Menu** (1) and select **Automate Infrastructure -> Clusters** (2).\n\n  ![](images/new-image-1.png)\n\n3. Initially, you shouldn't have any cluster registered here. Let's add our first cluster. Click **Add cluster**.\n\n  ![](images/2020-09-17-19-59-07.png)\n\n4. You can add a cluster by Importing an existing cluster or provisioning a new cluster using a Service Library. We use the first option. Select **Import an Existing cluster** (1) and click **Import** (2).\n\n  ![](images/2020-09-17-20-00-49.png)\n\n5. Enter **ocp311** for cluster name (1) and **ocp311** for namespace (2). You can view the yaml file and change the settings as needed (3). To import an OpenShift cluster no further changes are needed. Click **Generate command** to continue (4).\n\n  ![](images/new-image-3.png)\n\n6. A curl command is generated that you will use to add the new cluster. Click **Copy command** button (1) and click **View cluster** (2) to see the new hub-cluster details page.\n\n  ![](images/7-cluster-mgmt-img.png)\n\n7. Open the terminal window clicking the **OCP 3.11 Terminal** link on the desktop. The **OCP 311** windows has a blue background.\n\n  ![](images/new-image-4.png)\n\n8. Let's test the new context configuration. Run the command below to get the cluster nodes.\n\n  ```\n  oc get nodes\n  ```\n\n  ![](images/new-image-5.png)\n\n  Great, you are accessing the OCP 3.11 cluster. Now you are ready to execute the generated command.\n\n9. **Paste** the generated command that you previously copied in the clipboard.  When you run the command, several Kubernetes objects are created in the multicluster-endpoint namespace.\n\n  ![](images/new-image-6.png)\n\n  In case you will see the error like shown below, run the command again.\n\n  ![](images/new-image-7.png)\n\n  This error is a result of performance limitations of the Skytap environment - the final result should look like below:\n\n  ![](images/new-image-8.png)\n\n10. You can view the progress by entering the command:\n\n  ```\n  watch oc get pods -n multicluster-endpoint\n  ```\n\n  Make sure all the pods are in the running state.\n\n  ![](images/new-image-9.png)\n\n11. The cluster endpoint (klusterlet) is ready when all the Pods are in Running state (press CTRL+C to cancel the watch command). Back to the browser window, click **View cluster** and make sure that the cluster status is **Ready** now (if necessary, refresh the details page). On the page navigation breadcrumb, click on **Clusters** link.\n\n  ![](images/new-image-10.png)\n\n12. Now you can see your ocp311 cluster on the clusters list. You can add labels to identify your new cluster. On the hub-cluster row, click on the three dots icon (1) and select **Edit labels** (2).\n\n  ![](images/new-image-11.png)\n\n13. Add a new label, **environment** (1), and give a value **Dev** (2). Click **+** (3) and **save** (4) the changes.\n\n  ![](images/new-image-12.png)\n\n  Great, your first cluster is ready! Now let's add your MicroK8s managed cluster.\n\n14. Click **Add cluster** again.\n\n  ![](images/new-image-13.png)\n\n15. Select again **Import an Existing cluster** (1) and click **Import** (2).\n\n  ![](images/2020-09-17-20-00-49.png)\n\n16. Enter **microk8s** for cluster name (1) and **microk8s** for namespace (2). Click **Generate command** to continue (3).\n\n  ![](images/2020-09-17-20-26-25.png)\n\n17. A curl command is generated that you will use to add the new cluster. Click **Copy command** button (1).\n\n  ![](images/7-cluster-mgmt-img.png)\n\n18. Go back to the desktop and open the terminal window to MicroK8s cluster clicking the **MicroK8s Terminal** link.\n\n![](images/2020-09-17-20-30-28.png)\n\n19. MicroK8s terminal has a yellow background. To verify the cluster status run the following command in the **MicroK8s** window\n\n  ```\n  kubectl get nodes\n  ```\n\n  ![](images/2020-09-17-20-32-22.png)\n\n  Great, you are accessing the managed cluster. Now you are ready to execute the generated command.\n\n20. **Paste** the generated command that you previously copied in the clipboard. When you run the command, several Kubernetes objects are created in the multicluster-endpoint namespace.\n\n  ![](images/2020-09-17-20-33-29.png)\n\n  If you see the error as before - just run the command again.\n\n21. You can view the progress by entering the command:\n\n  ```\n  watch kubectl get pods -n multicluster-endpoint\n  ```\n\n  Make sure all the pods are in the running state (press CTRL+C to terminate the watch command).\n\n  ![](images/2020-09-17-20-35-48.png)\n\n22. Back to the browser window, click **View cluster** and make sure that the cluster status is **Ready** now (if necessary, refresh the details page).\n\n  ![](images/2020-09-17-20-37-12.png)\n\n  ![](images/2020-09-17-20-38-01.png)\n\n23. On the page navigation breadcrumb, click on **Clusters** link\n\n  ![](images/new-image-14.png)\n\n24. Now you can see your both clusters in a clusters list. You should add labels to identify your new cluster. Follow the same procedure as in steps 12-13 above to add a label **environment** = **QA** to the microK8s cluster\n\n  Great, your both clusters are ready and managed by IBM Cloud Pak for Multicloud Management. Using this Pak, you are able to manage both cluster from a single pane of glass. Let's check it in the next section.\n\n***\n\n## Define Application Channel\n\nIBM Cloud Pak for Multicloud Management provides enhanced application management capabilities through an improved application model and new deployment options. The new model and deployment options are designed to unify and simplify the deployment experience for creating and managing your applications across clusters.\n\nThe new application management capabilities use Channels and Subscriptions to gain improved continuous and automated delivery of deployables to target managed clusters.\n\nThe concept is similar to subscription model of TV channels. In this model, all the applications, which are packaged as helm charts, will be hosted in one or more repositories. The repositories, which contain the application packages, are defined as channels that broadcast across the clusters. If you want to deploy an application, then define a subscription to the channel with the name of the application (one or more) you want to deploy\n\n![](images/2-app-mgmt-img.png)\n\nChannels (Channel.app.ibm.com) define a namespace within the hub cluster and point to a physical place where resources are stored for deployment; such as an object store, Kubernetes namespace, or Helm repository.\n\n![](images/3-app-mgmt-img.png)\n\nIn this section, you define Application and Channel resources to deploy the Modresort application. The resources will be created using YAML files. The modresort application is a simple application with only one component.\n\n1.Back to the Desktop, open the Management Hub terminal window (green terminal).\n\n  ![](images/new-image-15.png)\n\n  To set the the context to use your Hub cluster (login to the cluster), run the command below:\n\n```\n./oclogin.sh\n```\n\n  ![](images/2020-09-17-20-02-48.png)\n\n2.Let's create our YAML files to define Channel, Application, Subscription, etc. To simplify the lab steps, you will clone a pre-created YAML. Don't worry, because we will understand them. To copy pre-created YAML files, let's use the Git CLI (if you don't have Git CLI, check [here](https://pages.github.ibm.com/demohub/cloudpak-mcm/labs/installcli/) how to install it). Run the command below:\n\n```\ngit clone https://github.com/rafosorio/appmgmtlab.git\n```\n\n```\ncd appmgmtlab\n```\n\n  ![](images/new-image-16.png)\n\n3.Now you have two folders (modresortchan and modresortapp). Let's start exploring the **modresortchan** and use any editor to see the content of the **channel.yaml** file.\n\n```\ncd modresortchan\n```\n```\nvi channel.yaml\n```\n\n4.Our channel.yaml has the content below.\n\n```\napiVersion: app.ibm.com/v1alpha1\nkind: Channel\nmetadata:\n  name: modresort-devchan\n  namespace: modresort-entitlement\n  labels:\n    app: modresortchan\nspec:\n  type: Namespace\n  pathname: modresort-entitlement\n```\n\n  It is a really simple file. The spec collection defines the type of the channel. In this lab, the channel is of type namespace, meaning that the yaml you create will be deployed and stored in OpenShift namespaces rather than in a Helm chart or Object store. This file is ready, and you don't need to edit it, go ahead and **close** the channel.yaml file.\n\n5.The modresort application component consists of a **deployment resource definition** and a **service resource definition**.\n\n  To enable these components to be used by the channel subscription, each of the resources need to be wrapped by a new custom resource definition (CRD) called Deployable.\n\n  Use your editor again and check now the **deployable.yaml** file.\n\n```\nvi deployable.yaml\n```\n\n```\napiVersion: app.ibm.com/v1alpha1\nkind: Deployable\nmetadata:\n  name: devchan-modresortchan-deployment\n  namespace: modresort-entitlement\n  annotations:\n    app.ibm.com/is-local-deployable: \"false\"\n  labels:\n    app: modresortchan\n    component: main\n    package: modresort\nspec:\n  template:\n    kind: Deployment\n    apiVersion: apps/v1\n    metadata:\n      name: devchan-modresortchan-deployment\n      labels:\n        app: modresortchan\n    spec:\n      selector:\n        matchLabels:\n          app: modresortchan\n          release: modresort-devchan\n          tier: frontend\n      replicas: 1\n      template:\n        metadata:\n          labels:\n            app: modresortchan\n            release: modresort-devchan\n            tier: frontend\n        spec:\n          containers:\n            - name: frontend\n              image: \"kpostreich/modresort:1.0\"\n              imagePullPolicy: Always\n              ports:\n                - containerPort: 9080\n              env:\n              - name: GET_HOSTS_FROM\n                value: dns\n              - name: WLP_LOGGING_CONSOLE_FORMAT\n                value: json\n              - name: WLP_LOGGING_CONSOLE_LOGLEVEL\n                value: info\n              - name: WLP_LOGGING_CONSOLE_SOURCE\n                value: message,trace,accessLog,ffdc\n---\napiVersion: app.ibm.com/v1alpha1\nkind: Deployable\nmetadata:\n  name: devchan-modresortchan-service\n  namespace: modresort-entitlement\n  annotations:\n    app.ibm.com/is-local-deployable: \"false\"\n  labels:\n    app: modresortchan\n    component: main\n    package: modresort\nspec:\n  template:\n    kind: Service\n    apiVersion: v1\n    metadata:\n      name: devchan-modresortchan-service\n      labels:\n        app: modresortchan\n    spec:\n      type: NodePort\n      ports:\n        - port: 9080\n      selector:\n        app: modresortchan\n        release: modresort-devchan\n        tier: frontend\n---\napiVersion: app.ibm.com/v1alpha1\nkind: Deployable\nmetadata:\n  name: devchan-modresortchan-route\n  namespace: modresort-entitlement\n  annotations:\n    app.ibm.com/is-local-deployable: \"false\"\n  labels:\n    app: modresortchan\n    component: main\n    package: modresort\nspec:\n  template:\n    apiVersion: route.openshift.io/v1\n    kind: Route\n    metadata:\n      labels:\n        app: devchan-modresortchan-route\n      name: modresorts\n    spec:\n      host: modresorts-default.10.0.0.15.nip.io\n      port:\n        targetPort: 9080\n      subdomain: \"\"\n      to:\n        kind: Service\n        name: devchan-modresortchan-service\n        weight: 100\n      wildcardPolicy: None\n```\n\n  There are three Deployables defined in the yaml file that wrap the modresort Kubernetes resources\n  - One for the modresort deployment, refers to the location of the Docker image;\n  - One for the modresort service, refers to the service port and defines a NodePort;\n  - One for the modresort routes, refers to domain name and exposes to the external network;\n\n  Refer to the [online documentation](https://www.ibm.com/support/knowledgecenter/en/SSFC4F_1.2.0/mcm/applications/managing_deployables.html) for details on the construct of the Deployable definition.\n\n  Next section, you learn how to create a subscription.\n\n***\n\n## Create a Subscription\n\nThe subscription to a channel package contains\n  -\tApplication Definition\n  - Placement Rules Definition\n  - Subscription Definition\n\n**Applications** (Application.app.k8s.io) in IBM Multicloud Manager are used for grouping application components.\n\n**Placement rules** (PlacementRule.app.ibm.com) define the target clusters where deployables can be deployed. You can use placement rules to help you facilitate the multi-cluster deployment of your deployables. Placement rules can be referenced by deployables and subscriptions.\n\n**Subscriptions** (Subscription.app.ibm.com) are sets of definitions that identify deployables within channels by using annotations, labels, and versions.\n\nThe subscription controller can monitor the channel for new or updated deployables, such as an updated Helm release or a new Kubernetes deployable object. Then, the controller can download the Kubernetes deployable object or Helm release directly from the source location (Helm repository, object store, or namespace) to the target managed clusters.\n\n1.Back to the Management Hub terminal window, let's explore the YAML files on modresortapp folder.\n\n```\ncd ../modresortapp\n```\n\n2.Now, using your editor again, open the **application.yaml**. Below is the content of the file:\n\n```\napiVersion: app.k8s.io/v1beta1\nkind: Application\nmetadata:\n  name: modresort101-modresortapp\n  namespace: modresort-project\n  labels:\n    app: modresortapp\nspec:\n  selector:\n    matchExpressions:\n    - key: release\n      operator: In\n      values:\n      - modresort101\n  componentKinds:\n  - group: app.ibm.com\n    kind: Subscription\n```\n\n  Here we have the definition of our modresort application. Refer to the [online documentation](https://www.ibm.com/support/knowledgecenter/en/SSFC4F_1.2.0/mcm/applications/app_lifecycle.html) for details on configuring the Application resource.\n\n3.**Close** the application.yaml file.\n\n4.Use your editor again, to explore the **placementrules.yaml** file. Below is the file's content:\n\n```\napiVersion: app.ibm.com/v1alpha1\nkind: PlacementRule\nmetadata:\n  name: modresortapp101-modresortapp\n  namespace: modresort-project\n  labels:\n    app: modresortapp\n    release: modresort101\nspec:\n  clusterReplicas: 1\n  clusterLabels:\n    matchLabels:\n      environment: Dev\n```\n\n  Placement Rules defines where and how Helm charts and deployables are deployed. Use placement rules to help you facilitate multi-cluster deployments of your deployables. Refer to the [online documentation](https://www.ibm.com/support/knowledgecenter/en/SSFC4F_1.2.0/mcm/applications/managing_placement_rules.html) for details on configuring the Placement Rules resource.\n\n  In your case, the placementrules.yaml is defining to deploy the modresortapp in Dev environment only.\n\n5.**Close** the placementrules.yaml file.\n\n6.Now, let’s explore the **subscription.yaml** file.\n\n```\napiVersion: app.ibm.com/v1alpha1\nkind: Subscription\nmetadata:\n  name: modresort101-modresortapp\n  namespace: modresort-project\n  labels:\n    app: modresortapp\n    release: modresort101\nspec:\n  channel: modresort-entitlement/modresort-devchan\n  name: \"\"\n  packageFilter:\n    version: \">=1.x\"\n    labelSelector:\n      matchLabels:\n        package: modresort\n        component: main\n  placement:\n    placementRef:\n      name: modresortapp101-modresortapp\n      kind: PlacementRule\n      group: app.ibm.com\n  overrides:\n  - clusterName: \"/\"\n    clusterOverrides:\n    - path: \"metadata.namespace\"\n      value: default\n```\n\n  This contains the details of relating the placement rule definition with the application specification. Refer to the [online documentation](https://www.ibm.com/support/knowledgecenter/en/SSFC4F_1.2.0/mcm/applications/managing_subscriptions.html) for details on configuring the Subscription resource.\n\n7.**Close** the subscription.yaml file. All your files are ready to deploy the application.\n\n  This completes enabling an existing application with policies so that they can be deployed to any Kubernetes managed cluster. Next section, you deploy the application using the channel and subscription created here.\n\n***\n\n## Deploy the Application\n\nIn this section, you will deploy the application components to their respective Kubernetes namespaces, using the yaml files that you created in the previous task.\n\n1.Back to the Management Hub terminal window, execute the command bellow to create two new Openshift projects.\n\n```\noc new-project modresort-project\n```\n\n```\noc new-project modresort-entitlement\n```\n\n  ![](images/new-image-17.png)\n\n2.Now, let’s deploy the modresortchan. Execute the commands below:\n\n```\ncd ..\n```\n\n```\noc apply -f modresortchan\n```\n\n  The output of the above command will be similar to the illustration below. The output shows that Channel and Deployables are deployed.\n\n  ![](images/new-image-18.png)\n\n3.The subscription is deployed to a different namespace than the channel. Never deploy the subscription to the same namespace as the channel. Hence, deploy the subscription to the other namespace, modresort-project.\n\n```\noc project modresort-project\n```\n\n```\noc apply -f modresortapp\n```\n\n  ![](images/new-image-19.png)\n\n  Next section of the lab will walk you through validating the application deployment.\n\n***\n\n## Validate the Application\n\nThe Application view in Cloud Pak for Multicloud Management console provides graphical view into the applications, channels and subscriptions deployed in the clusters. Let’s validate if the modresort application is deployed correctly.\n\n1.Back to the Firefox browser, you should be in your Cloud Pak for Multicloud Management Web Console.\n\n  ![](images/10-app-mgmt-img.png)\n\n2.On the top left of the page, open the **Menu** (1) and select **Manage Applications** (2) and click on **Hybrid applications** (3).\n\n  ![](images/new-image-20.png)\n\n3.Click on the **modresort101-modresortapp** application link to get to the application Overview page.\n\n  ![](images/new-image-21.png)\n\n4.Scroll down to view the application diagram.\n\n  ![](images/new-image-22.png)\n\n  *Note: It may take a couple of minutes for the application to deploy to the cluster.*\n\n  When the application is successfully deployed via the subscription, the pod in the application topology view will have a green icon as illustrated below.\n\n  ![](images/14-app-mgmt-img.png)\n\n  `Note (Only if you have issues): After a couple of minutes, if your pod has a yellow icon next to the pod, indicating it is in an unknown state, you will need to troubleshoot your yaml files for correctness and redeploy the resources.   Verify that your subscriptions are propagated correctly by running the command.`\n\n```\noc get subscription.app.ibm.com --all-namespaces\n```\n\n  The subscription from the **modresort** should be in the **Propagated** state.\n\n5.Back to OCP311 terminal window (blue window), let’s check the pods are in running state.\n\n```\noc get pods -n default\n```\n\n  You should see the devchan-modresort-deployment pod running in the default namespace\n\n  ![](images/new-image-23.png)\n\n6.Use the command line to get the devchan-modresortchan-service NodePort.\n\n```\noc get services -n default\n```\n\n  ![](images/new-image-24.png)\n\n  Take note of the devchan-modresortchan-service nodePort (on the picture above is 30606), you will use it to access your application.\n\n7.Back to the browser, open a new tab and navigate to:\n\n```\nhttp://ocp311:<NodePort>/resorts\n```\n  For example, http://ocp311:32664/resorts\n\n  ![](images/new-image-25.png)\n\n  Congratulations! You have successfully deployed the modresorts application to the OpenShift 3.11 Cluster.\n\n***\n\n## Move the Application\n\nApplications deployed using the Subscription model are deployed to clusters based on PlacementRules. The placement rules for deployables can be defined as a stand-alone resource and referenced by the deployable. The placement rules use cluster labels to determine where to place the applications.\n\nIn the following steps, you will move the application from the Dev cluster to the QA cluster by changing the placement policy. You also learn how to use cluster replicas.\n\n1.Currently, the application deployed as running on Dev cluster because of the placement values specified in application, as you verified earlier.\n\n  You can modify the placement policies from application view by selecting the placement policy and modifying the corresponding values in the yaml file. Let’s do it!\n\n  Back to the Multicloud Management page, on the Resource topology chart, click on the **modresortapp101 placement policy** icon.\n\n  ![](images/18-app-mgmt-img.png)\n\n2.On the Editor, modify the environment setting from Dev to QA.\n\n  ![](images/new-image-26.png)\n\n3.Apply changes by clicking on **update** icon as shown below.\n\n  ![](images/20-app-mgmt-img.png)\n\n4.Within a few minutes, the cluster value changes from ocp311 to microk8s, and the application is now running on microk8s cluster.\n\n  ![](images/new-image-27.png)\n\n5.Let’s verify that the application is actually running on MicroK8s cluster. Go back to the yellow MicroK8s terminal windows and execute the following commands:\n\n```\nkubectl get pods -n default\nkubectl get service -n default\n```\n\n  ![](images/new-image-28.png)\n\n6.Notice the **Node port** used by the service. In the example screenshot it is `30726`.\n\n  ![](images/new-image-29.png)\n\n7.Go back to your browser window, open a new tab and provide the following URL:\n  `http://microk8s:[port-number-from-previous-step]/resorts`\n\n  ![](images/new-image-30.png)\n\n  Great, you moved the application from one cluster to the other.\n\n8.What if you want to run the application on both the clusters? This is possible by changing clusterReplicas and matchingLabel. Let’s do it!\n\n  Back to the Multicluster Management page, on the Editor, change **clusterReplicas** to **2**.\n\n  ![](images/new-image-31.png)\n\n9.On the spec **matchLabels** setting, **remove** the **environment label**, and add **cloud** label with value **Other**.\n\n  ![](images/new-image-32.png)\n\n  The label, cloud, exists on both the clusters and the value matches Other.\n\n12.Apply the changes by clicking update icon.\n\n  ![](images/27-app-mgmt-img.png)\n\n13.Within a few minutes, the resource overview refreshes, indicating that the application is running on both clusters. You can validate by checking the status of pods on both the clusters\n\n  ![](images/new-image-33.png)\n\n  Great, now you have your application on both clusters. Next section, you explore Grafana dashboard to visualize the application health across clusters.\n\n  Congratulations! You have successfully completed the lab “Application Management with IBM Cloud Pak for Multicloud Management”.\n\n***\n\n## Summary\n\nYou completed the Cloud Pak for Multicloud Management tutorial: Multi-cluster Management. Throughout the tutorial, you explored the key takeaways:\n- `Understand Cloud Pak for Multicloud Management`\n-\t`Define an application with Channels and Subscriptions`\n-\t`Deploy the application chart from the catalog`\n-\t`Modify Placement Policies to move application resources across clusters`\n-\t`Check the application health by using Federated Prometheus Dashboard`\n\n\nIf you would like to learn more about Cloud Pak for Multicloud Management, please refer to:\n-\t<a href=\"https://www.ibm.com/cloud/cloud-pak-for-management\" target=\"blank\">Cloud Pak for Multicloud Management home page</a>\n- <a href=\"https://www.ibm.com/demos/collection/Cloud-Pak-for-Multicloud-Management\" target=\"blank\">Cloud Pak for Multicloud Management Demos </a>\n","type":"Mdx","contentDigest":"94201ec6185bb9a36df322c27cd1272d","counter":1523,"owner":"gatsby-plugin-mdx"},"frontmatter":{"title":"Lab 2 - Application Management","description":null},"exports":{},"rawBody":"---\ntitle: Lab 2 - Application Management\ndescription:\n---\n\n<FeatureCard\n  title=\"Application Management with IBM Cloud Pak for Multicloud Management\"\n  color=\"dark\"\n  >\n\n![banner](/images/appmgmt-banner.jpg)\n\n</FeatureCard>\n\n\n<AnchorLinks>\n  <AnchorLink>Lab Overview</AnchorLink>\n  <AnchorLink>Prerequisite</AnchorLink>\n  <AnchorLink>Business Context</AnchorLink>\n  <AnchorLink>Define Application Channel</AnchorLink>\n  <AnchorLink>Create a Subscription</AnchorLink>\n  <AnchorLink>Deploy the Application</AnchorLink>\n  <AnchorLink>Validate the Application</AnchorLink>\n  <AnchorLink>Move the Application</AnchorLink>\n  <AnchorLink>Summary</AnchorLink>\n</AnchorLinks>\n\n***\n\n## Lab Overview\n\nIBM Cloud Pak for Multicloud Management provides consistent visibility, automation, and governance across a range of multicloud management capabilities such as cost and asset management, infrastructure management, application management, multi-cluster management, edge management, and integration with existing tools and processes. Customers can leverage Cloud Pak for Multicloud Management to simplify their IT and application ops management, while increasing flexibility and cost savings with intelligent data analysis driven by predictive signals.\n\nCustomers can leverage IBM Cloud Pak for Multicloud Management to simplify their IT and application ops management, while increasing flexibility and cost savings with intelligent data analysis driven by predictive signals.\n\nIn this tutorial, you will explore the following key capabilities:\n-\t`Understand Cloud Pak for Multicloud Management`\n-\t`Deploy an application using Channels and Subscriptions`\n-\t`Move the application between clusters using Placement Policies`\n-\t`Visualize the application health using Grafana dashboards`\n\n***\n\n## Prerequisite\n\n- You need to provision your own copy of the CP4MCM 2.0 environment, start it and verify for correct startup (check [here](../../gettingstarted/)).\n\n***\n\n## Business Context\n\nAs a member of the Cloud Operation team, you are having problems to manage your multicloud hybrid world. Operate your cloud-based services and data across multiple providers is overwhelming your team.\nYour company is deploying multiple Kubernetes clusters to address their specific needs. Some Dev teams are deploying clusters across public and private clouds, and some are deploying clusters across regions, and some are deploying clusters to support the development and test needs.\n\nAs different teams deploy more clusters, new challenges are introduced:\n-\tWhere are my services running?\n-\tHow can I monitor applications across clusters and clouds?\n-\tHow can I manage clusters as if they were one environment?\n-\tHow do I monitor usage across clouds?\n-\tWhere are the failed components?\n-\tHow do I deploy applications across these environments?\n-\tHow do I move workloads across environments?\n-\tHow do I set consistent security policies across environments?\n-\tWhich clusters are compliant?\n-\tHow can I place workloads based on capacity, policy?\n\nBecause of that, you want to explore how IBM Cloud Pak for Multicloud Management, provides consistent visibility, governance and automation of your complex environment.\n\nIBM Cloud Pak for Multicloud Management provides enhanced application management capabilities through an improved application model and deployment options. The concept helps simplify and streamline application life cycle management across clusters.\n\nIn this tutorial, you will be using a sample Modresort application to demonstrate how to deploy an application in multiple clusters using channels and subscriptions. The Modresort is a WebSphere Liberty Java application available in Dockerhub.\n\n![](images/1-app-mgmt-img.png)\n\nIn this tutorial, you use two Red Hat OpenShift clusters.\n-\tHub-cluster is the Hub cluster that includes management console, federated monitoring, and all the controllers. In this Lab, you identify the hub-cluster with the label Dev for environment.\n-\tManaged-cluster is an Openshift cluster managed by the Hub cluster. In this Lab, you identify the managed cluster with the label QA for environment\n\nYou will complete the following tasks:\n-\t`Deploy Modresort application using Channels and Subscriptions`\n-\t`Move the application between clusters using Placement Policies`\n-\t`Visualize application health by using Grafana dashboard`\n\n***\n\n## Add Managed Clusters\n\nIn this section, you will add two new managed clusters in your Control Panel. As explained before, you will add your OpenShift Hub cluster and your Microk8s managed cluster.\n\n1. To start the lab, you should be in your Cloud Pak for Multicloud Management Web Console. If you are not, check [here](../gettingstarted/) how to open your console page.\n\n  ![](images/2-cluster-mgmt-img.png)\n\n2. Now, let's explore the Cluster view. Click the hamburger **Menu** (1) and select **Automate Infrastructure -> Clusters** (2).\n\n  ![](images/new-image-1.png)\n\n3. Initially, you shouldn't have any cluster registered here. Let's add our first cluster. Click **Add cluster**.\n\n  ![](images/2020-09-17-19-59-07.png)\n\n4. You can add a cluster by Importing an existing cluster or provisioning a new cluster using a Service Library. We use the first option. Select **Import an Existing cluster** (1) and click **Import** (2).\n\n  ![](images/2020-09-17-20-00-49.png)\n\n5. Enter **ocp311** for cluster name (1) and **ocp311** for namespace (2). You can view the yaml file and change the settings as needed (3). To import an OpenShift cluster no further changes are needed. Click **Generate command** to continue (4).\n\n  ![](images/new-image-3.png)\n\n6. A curl command is generated that you will use to add the new cluster. Click **Copy command** button (1) and click **View cluster** (2) to see the new hub-cluster details page.\n\n  ![](images/7-cluster-mgmt-img.png)\n\n7. Open the terminal window clicking the **OCP 3.11 Terminal** link on the desktop. The **OCP 311** windows has a blue background.\n\n  ![](images/new-image-4.png)\n\n8. Let's test the new context configuration. Run the command below to get the cluster nodes.\n\n  ```\n  oc get nodes\n  ```\n\n  ![](images/new-image-5.png)\n\n  Great, you are accessing the OCP 3.11 cluster. Now you are ready to execute the generated command.\n\n9. **Paste** the generated command that you previously copied in the clipboard.  When you run the command, several Kubernetes objects are created in the multicluster-endpoint namespace.\n\n  ![](images/new-image-6.png)\n\n  In case you will see the error like shown below, run the command again.\n\n  ![](images/new-image-7.png)\n\n  This error is a result of performance limitations of the Skytap environment - the final result should look like below:\n\n  ![](images/new-image-8.png)\n\n10. You can view the progress by entering the command:\n\n  ```\n  watch oc get pods -n multicluster-endpoint\n  ```\n\n  Make sure all the pods are in the running state.\n\n  ![](images/new-image-9.png)\n\n11. The cluster endpoint (klusterlet) is ready when all the Pods are in Running state (press CTRL+C to cancel the watch command). Back to the browser window, click **View cluster** and make sure that the cluster status is **Ready** now (if necessary, refresh the details page). On the page navigation breadcrumb, click on **Clusters** link.\n\n  ![](images/new-image-10.png)\n\n12. Now you can see your ocp311 cluster on the clusters list. You can add labels to identify your new cluster. On the hub-cluster row, click on the three dots icon (1) and select **Edit labels** (2).\n\n  ![](images/new-image-11.png)\n\n13. Add a new label, **environment** (1), and give a value **Dev** (2). Click **+** (3) and **save** (4) the changes.\n\n  ![](images/new-image-12.png)\n\n  Great, your first cluster is ready! Now let's add your MicroK8s managed cluster.\n\n14. Click **Add cluster** again.\n\n  ![](images/new-image-13.png)\n\n15. Select again **Import an Existing cluster** (1) and click **Import** (2).\n\n  ![](images/2020-09-17-20-00-49.png)\n\n16. Enter **microk8s** for cluster name (1) and **microk8s** for namespace (2). Click **Generate command** to continue (3).\n\n  ![](images/2020-09-17-20-26-25.png)\n\n17. A curl command is generated that you will use to add the new cluster. Click **Copy command** button (1).\n\n  ![](images/7-cluster-mgmt-img.png)\n\n18. Go back to the desktop and open the terminal window to MicroK8s cluster clicking the **MicroK8s Terminal** link.\n\n![](images/2020-09-17-20-30-28.png)\n\n19. MicroK8s terminal has a yellow background. To verify the cluster status run the following command in the **MicroK8s** window\n\n  ```\n  kubectl get nodes\n  ```\n\n  ![](images/2020-09-17-20-32-22.png)\n\n  Great, you are accessing the managed cluster. Now you are ready to execute the generated command.\n\n20. **Paste** the generated command that you previously copied in the clipboard. When you run the command, several Kubernetes objects are created in the multicluster-endpoint namespace.\n\n  ![](images/2020-09-17-20-33-29.png)\n\n  If you see the error as before - just run the command again.\n\n21. You can view the progress by entering the command:\n\n  ```\n  watch kubectl get pods -n multicluster-endpoint\n  ```\n\n  Make sure all the pods are in the running state (press CTRL+C to terminate the watch command).\n\n  ![](images/2020-09-17-20-35-48.png)\n\n22. Back to the browser window, click **View cluster** and make sure that the cluster status is **Ready** now (if necessary, refresh the details page).\n\n  ![](images/2020-09-17-20-37-12.png)\n\n  ![](images/2020-09-17-20-38-01.png)\n\n23. On the page navigation breadcrumb, click on **Clusters** link\n\n  ![](images/new-image-14.png)\n\n24. Now you can see your both clusters in a clusters list. You should add labels to identify your new cluster. Follow the same procedure as in steps 12-13 above to add a label **environment** = **QA** to the microK8s cluster\n\n  Great, your both clusters are ready and managed by IBM Cloud Pak for Multicloud Management. Using this Pak, you are able to manage both cluster from a single pane of glass. Let's check it in the next section.\n\n***\n\n## Define Application Channel\n\nIBM Cloud Pak for Multicloud Management provides enhanced application management capabilities through an improved application model and new deployment options. The new model and deployment options are designed to unify and simplify the deployment experience for creating and managing your applications across clusters.\n\nThe new application management capabilities use Channels and Subscriptions to gain improved continuous and automated delivery of deployables to target managed clusters.\n\nThe concept is similar to subscription model of TV channels. In this model, all the applications, which are packaged as helm charts, will be hosted in one or more repositories. The repositories, which contain the application packages, are defined as channels that broadcast across the clusters. If you want to deploy an application, then define a subscription to the channel with the name of the application (one or more) you want to deploy\n\n![](images/2-app-mgmt-img.png)\n\nChannels (Channel.app.ibm.com) define a namespace within the hub cluster and point to a physical place where resources are stored for deployment; such as an object store, Kubernetes namespace, or Helm repository.\n\n![](images/3-app-mgmt-img.png)\n\nIn this section, you define Application and Channel resources to deploy the Modresort application. The resources will be created using YAML files. The modresort application is a simple application with only one component.\n\n1.Back to the Desktop, open the Management Hub terminal window (green terminal).\n\n  ![](images/new-image-15.png)\n\n  To set the the context to use your Hub cluster (login to the cluster), run the command below:\n\n```\n./oclogin.sh\n```\n\n  ![](images/2020-09-17-20-02-48.png)\n\n2.Let's create our YAML files to define Channel, Application, Subscription, etc. To simplify the lab steps, you will clone a pre-created YAML. Don't worry, because we will understand them. To copy pre-created YAML files, let's use the Git CLI (if you don't have Git CLI, check [here](https://pages.github.ibm.com/demohub/cloudpak-mcm/labs/installcli/) how to install it). Run the command below:\n\n```\ngit clone https://github.com/rafosorio/appmgmtlab.git\n```\n\n```\ncd appmgmtlab\n```\n\n  ![](images/new-image-16.png)\n\n3.Now you have two folders (modresortchan and modresortapp). Let's start exploring the **modresortchan** and use any editor to see the content of the **channel.yaml** file.\n\n```\ncd modresortchan\n```\n```\nvi channel.yaml\n```\n\n4.Our channel.yaml has the content below.\n\n```\napiVersion: app.ibm.com/v1alpha1\nkind: Channel\nmetadata:\n  name: modresort-devchan\n  namespace: modresort-entitlement\n  labels:\n    app: modresortchan\nspec:\n  type: Namespace\n  pathname: modresort-entitlement\n```\n\n  It is a really simple file. The spec collection defines the type of the channel. In this lab, the channel is of type namespace, meaning that the yaml you create will be deployed and stored in OpenShift namespaces rather than in a Helm chart or Object store. This file is ready, and you don't need to edit it, go ahead and **close** the channel.yaml file.\n\n5.The modresort application component consists of a **deployment resource definition** and a **service resource definition**.\n\n  To enable these components to be used by the channel subscription, each of the resources need to be wrapped by a new custom resource definition (CRD) called Deployable.\n\n  Use your editor again and check now the **deployable.yaml** file.\n\n```\nvi deployable.yaml\n```\n\n```\napiVersion: app.ibm.com/v1alpha1\nkind: Deployable\nmetadata:\n  name: devchan-modresortchan-deployment\n  namespace: modresort-entitlement\n  annotations:\n    app.ibm.com/is-local-deployable: \"false\"\n  labels:\n    app: modresortchan\n    component: main\n    package: modresort\nspec:\n  template:\n    kind: Deployment\n    apiVersion: apps/v1\n    metadata:\n      name: devchan-modresortchan-deployment\n      labels:\n        app: modresortchan\n    spec:\n      selector:\n        matchLabels:\n          app: modresortchan\n          release: modresort-devchan\n          tier: frontend\n      replicas: 1\n      template:\n        metadata:\n          labels:\n            app: modresortchan\n            release: modresort-devchan\n            tier: frontend\n        spec:\n          containers:\n            - name: frontend\n              image: \"kpostreich/modresort:1.0\"\n              imagePullPolicy: Always\n              ports:\n                - containerPort: 9080\n              env:\n              - name: GET_HOSTS_FROM\n                value: dns\n              - name: WLP_LOGGING_CONSOLE_FORMAT\n                value: json\n              - name: WLP_LOGGING_CONSOLE_LOGLEVEL\n                value: info\n              - name: WLP_LOGGING_CONSOLE_SOURCE\n                value: message,trace,accessLog,ffdc\n---\napiVersion: app.ibm.com/v1alpha1\nkind: Deployable\nmetadata:\n  name: devchan-modresortchan-service\n  namespace: modresort-entitlement\n  annotations:\n    app.ibm.com/is-local-deployable: \"false\"\n  labels:\n    app: modresortchan\n    component: main\n    package: modresort\nspec:\n  template:\n    kind: Service\n    apiVersion: v1\n    metadata:\n      name: devchan-modresortchan-service\n      labels:\n        app: modresortchan\n    spec:\n      type: NodePort\n      ports:\n        - port: 9080\n      selector:\n        app: modresortchan\n        release: modresort-devchan\n        tier: frontend\n---\napiVersion: app.ibm.com/v1alpha1\nkind: Deployable\nmetadata:\n  name: devchan-modresortchan-route\n  namespace: modresort-entitlement\n  annotations:\n    app.ibm.com/is-local-deployable: \"false\"\n  labels:\n    app: modresortchan\n    component: main\n    package: modresort\nspec:\n  template:\n    apiVersion: route.openshift.io/v1\n    kind: Route\n    metadata:\n      labels:\n        app: devchan-modresortchan-route\n      name: modresorts\n    spec:\n      host: modresorts-default.10.0.0.15.nip.io\n      port:\n        targetPort: 9080\n      subdomain: \"\"\n      to:\n        kind: Service\n        name: devchan-modresortchan-service\n        weight: 100\n      wildcardPolicy: None\n```\n\n  There are three Deployables defined in the yaml file that wrap the modresort Kubernetes resources\n  - One for the modresort deployment, refers to the location of the Docker image;\n  - One for the modresort service, refers to the service port and defines a NodePort;\n  - One for the modresort routes, refers to domain name and exposes to the external network;\n\n  Refer to the [online documentation](https://www.ibm.com/support/knowledgecenter/en/SSFC4F_1.2.0/mcm/applications/managing_deployables.html) for details on the construct of the Deployable definition.\n\n  Next section, you learn how to create a subscription.\n\n***\n\n## Create a Subscription\n\nThe subscription to a channel package contains\n  -\tApplication Definition\n  - Placement Rules Definition\n  - Subscription Definition\n\n**Applications** (Application.app.k8s.io) in IBM Multicloud Manager are used for grouping application components.\n\n**Placement rules** (PlacementRule.app.ibm.com) define the target clusters where deployables can be deployed. You can use placement rules to help you facilitate the multi-cluster deployment of your deployables. Placement rules can be referenced by deployables and subscriptions.\n\n**Subscriptions** (Subscription.app.ibm.com) are sets of definitions that identify deployables within channels by using annotations, labels, and versions.\n\nThe subscription controller can monitor the channel for new or updated deployables, such as an updated Helm release or a new Kubernetes deployable object. Then, the controller can download the Kubernetes deployable object or Helm release directly from the source location (Helm repository, object store, or namespace) to the target managed clusters.\n\n1.Back to the Management Hub terminal window, let's explore the YAML files on modresortapp folder.\n\n```\ncd ../modresortapp\n```\n\n2.Now, using your editor again, open the **application.yaml**. Below is the content of the file:\n\n```\napiVersion: app.k8s.io/v1beta1\nkind: Application\nmetadata:\n  name: modresort101-modresortapp\n  namespace: modresort-project\n  labels:\n    app: modresortapp\nspec:\n  selector:\n    matchExpressions:\n    - key: release\n      operator: In\n      values:\n      - modresort101\n  componentKinds:\n  - group: app.ibm.com\n    kind: Subscription\n```\n\n  Here we have the definition of our modresort application. Refer to the [online documentation](https://www.ibm.com/support/knowledgecenter/en/SSFC4F_1.2.0/mcm/applications/app_lifecycle.html) for details on configuring the Application resource.\n\n3.**Close** the application.yaml file.\n\n4.Use your editor again, to explore the **placementrules.yaml** file. Below is the file's content:\n\n```\napiVersion: app.ibm.com/v1alpha1\nkind: PlacementRule\nmetadata:\n  name: modresortapp101-modresortapp\n  namespace: modresort-project\n  labels:\n    app: modresortapp\n    release: modresort101\nspec:\n  clusterReplicas: 1\n  clusterLabels:\n    matchLabels:\n      environment: Dev\n```\n\n  Placement Rules defines where and how Helm charts and deployables are deployed. Use placement rules to help you facilitate multi-cluster deployments of your deployables. Refer to the [online documentation](https://www.ibm.com/support/knowledgecenter/en/SSFC4F_1.2.0/mcm/applications/managing_placement_rules.html) for details on configuring the Placement Rules resource.\n\n  In your case, the placementrules.yaml is defining to deploy the modresortapp in Dev environment only.\n\n5.**Close** the placementrules.yaml file.\n\n6.Now, let’s explore the **subscription.yaml** file.\n\n```\napiVersion: app.ibm.com/v1alpha1\nkind: Subscription\nmetadata:\n  name: modresort101-modresortapp\n  namespace: modresort-project\n  labels:\n    app: modresortapp\n    release: modresort101\nspec:\n  channel: modresort-entitlement/modresort-devchan\n  name: \"\"\n  packageFilter:\n    version: \">=1.x\"\n    labelSelector:\n      matchLabels:\n        package: modresort\n        component: main\n  placement:\n    placementRef:\n      name: modresortapp101-modresortapp\n      kind: PlacementRule\n      group: app.ibm.com\n  overrides:\n  - clusterName: \"/\"\n    clusterOverrides:\n    - path: \"metadata.namespace\"\n      value: default\n```\n\n  This contains the details of relating the placement rule definition with the application specification. Refer to the [online documentation](https://www.ibm.com/support/knowledgecenter/en/SSFC4F_1.2.0/mcm/applications/managing_subscriptions.html) for details on configuring the Subscription resource.\n\n7.**Close** the subscription.yaml file. All your files are ready to deploy the application.\n\n  This completes enabling an existing application with policies so that they can be deployed to any Kubernetes managed cluster. Next section, you deploy the application using the channel and subscription created here.\n\n***\n\n## Deploy the Application\n\nIn this section, you will deploy the application components to their respective Kubernetes namespaces, using the yaml files that you created in the previous task.\n\n1.Back to the Management Hub terminal window, execute the command bellow to create two new Openshift projects.\n\n```\noc new-project modresort-project\n```\n\n```\noc new-project modresort-entitlement\n```\n\n  ![](images/new-image-17.png)\n\n2.Now, let’s deploy the modresortchan. Execute the commands below:\n\n```\ncd ..\n```\n\n```\noc apply -f modresortchan\n```\n\n  The output of the above command will be similar to the illustration below. The output shows that Channel and Deployables are deployed.\n\n  ![](images/new-image-18.png)\n\n3.The subscription is deployed to a different namespace than the channel. Never deploy the subscription to the same namespace as the channel. Hence, deploy the subscription to the other namespace, modresort-project.\n\n```\noc project modresort-project\n```\n\n```\noc apply -f modresortapp\n```\n\n  ![](images/new-image-19.png)\n\n  Next section of the lab will walk you through validating the application deployment.\n\n***\n\n## Validate the Application\n\nThe Application view in Cloud Pak for Multicloud Management console provides graphical view into the applications, channels and subscriptions deployed in the clusters. Let’s validate if the modresort application is deployed correctly.\n\n1.Back to the Firefox browser, you should be in your Cloud Pak for Multicloud Management Web Console.\n\n  ![](images/10-app-mgmt-img.png)\n\n2.On the top left of the page, open the **Menu** (1) and select **Manage Applications** (2) and click on **Hybrid applications** (3).\n\n  ![](images/new-image-20.png)\n\n3.Click on the **modresort101-modresortapp** application link to get to the application Overview page.\n\n  ![](images/new-image-21.png)\n\n4.Scroll down to view the application diagram.\n\n  ![](images/new-image-22.png)\n\n  *Note: It may take a couple of minutes for the application to deploy to the cluster.*\n\n  When the application is successfully deployed via the subscription, the pod in the application topology view will have a green icon as illustrated below.\n\n  ![](images/14-app-mgmt-img.png)\n\n  `Note (Only if you have issues): After a couple of minutes, if your pod has a yellow icon next to the pod, indicating it is in an unknown state, you will need to troubleshoot your yaml files for correctness and redeploy the resources.   Verify that your subscriptions are propagated correctly by running the command.`\n\n```\noc get subscription.app.ibm.com --all-namespaces\n```\n\n  The subscription from the **modresort** should be in the **Propagated** state.\n\n5.Back to OCP311 terminal window (blue window), let’s check the pods are in running state.\n\n```\noc get pods -n default\n```\n\n  You should see the devchan-modresort-deployment pod running in the default namespace\n\n  ![](images/new-image-23.png)\n\n6.Use the command line to get the devchan-modresortchan-service NodePort.\n\n```\noc get services -n default\n```\n\n  ![](images/new-image-24.png)\n\n  Take note of the devchan-modresortchan-service nodePort (on the picture above is 30606), you will use it to access your application.\n\n7.Back to the browser, open a new tab and navigate to:\n\n```\nhttp://ocp311:<NodePort>/resorts\n```\n  For example, http://ocp311:32664/resorts\n\n  ![](images/new-image-25.png)\n\n  Congratulations! You have successfully deployed the modresorts application to the OpenShift 3.11 Cluster.\n\n***\n\n## Move the Application\n\nApplications deployed using the Subscription model are deployed to clusters based on PlacementRules. The placement rules for deployables can be defined as a stand-alone resource and referenced by the deployable. The placement rules use cluster labels to determine where to place the applications.\n\nIn the following steps, you will move the application from the Dev cluster to the QA cluster by changing the placement policy. You also learn how to use cluster replicas.\n\n1.Currently, the application deployed as running on Dev cluster because of the placement values specified in application, as you verified earlier.\n\n  You can modify the placement policies from application view by selecting the placement policy and modifying the corresponding values in the yaml file. Let’s do it!\n\n  Back to the Multicloud Management page, on the Resource topology chart, click on the **modresortapp101 placement policy** icon.\n\n  ![](images/18-app-mgmt-img.png)\n\n2.On the Editor, modify the environment setting from Dev to QA.\n\n  ![](images/new-image-26.png)\n\n3.Apply changes by clicking on **update** icon as shown below.\n\n  ![](images/20-app-mgmt-img.png)\n\n4.Within a few minutes, the cluster value changes from ocp311 to microk8s, and the application is now running on microk8s cluster.\n\n  ![](images/new-image-27.png)\n\n5.Let’s verify that the application is actually running on MicroK8s cluster. Go back to the yellow MicroK8s terminal windows and execute the following commands:\n\n```\nkubectl get pods -n default\nkubectl get service -n default\n```\n\n  ![](images/new-image-28.png)\n\n6.Notice the **Node port** used by the service. In the example screenshot it is `30726`.\n\n  ![](images/new-image-29.png)\n\n7.Go back to your browser window, open a new tab and provide the following URL:\n  `http://microk8s:[port-number-from-previous-step]/resorts`\n\n  ![](images/new-image-30.png)\n\n  Great, you moved the application from one cluster to the other.\n\n8.What if you want to run the application on both the clusters? This is possible by changing clusterReplicas and matchingLabel. Let’s do it!\n\n  Back to the Multicluster Management page, on the Editor, change **clusterReplicas** to **2**.\n\n  ![](images/new-image-31.png)\n\n9.On the spec **matchLabels** setting, **remove** the **environment label**, and add **cloud** label with value **Other**.\n\n  ![](images/new-image-32.png)\n\n  The label, cloud, exists on both the clusters and the value matches Other.\n\n12.Apply the changes by clicking update icon.\n\n  ![](images/27-app-mgmt-img.png)\n\n13.Within a few minutes, the resource overview refreshes, indicating that the application is running on both clusters. You can validate by checking the status of pods on both the clusters\n\n  ![](images/new-image-33.png)\n\n  Great, now you have your application on both clusters. Next section, you explore Grafana dashboard to visualize the application health across clusters.\n\n  Congratulations! You have successfully completed the lab “Application Management with IBM Cloud Pak for Multicloud Management”.\n\n***\n\n## Summary\n\nYou completed the Cloud Pak for Multicloud Management tutorial: Multi-cluster Management. Throughout the tutorial, you explored the key takeaways:\n- `Understand Cloud Pak for Multicloud Management`\n-\t`Define an application with Channels and Subscriptions`\n-\t`Deploy the application chart from the catalog`\n-\t`Modify Placement Policies to move application resources across clusters`\n-\t`Check the application health by using Federated Prometheus Dashboard`\n\n\nIf you would like to learn more about Cloud Pak for Multicloud Management, please refer to:\n-\t<a href=\"https://www.ibm.com/cloud/cloud-pak-for-management\" target=\"blank\">Cloud Pak for Multicloud Management home page</a>\n- <a href=\"https://www.ibm.com/demos/collection/Cloud-Pak-for-Multicloud-Management\" target=\"blank\">Cloud Pak for Multicloud Management Demos </a>\n","fileAbsolutePath":"/Users/dymaczew/Documents/_code/mcm/cp4mcm-demohub/src/pages/labs/appmgmt/index.mdx"}}},"staticQueryHashes":["1364590287","2102389209","2102389209","227138135","227138135","2456312558","2746626797","2746626797","3018647132","3018647132","3906363820","3906363820","768070550"]}